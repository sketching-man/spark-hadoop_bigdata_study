# Apacke Spark (= 아파치 스파크)

스파크는, 빅 데이터에 대한 컴퓨팅 연산을 다수의 서버로 구성된 클러스터에서 분산 병렬 처리하기 위한 오픈소스 엔진.  
물론 싱글 노드 환경에서도 병렬 처리 엔진으로 쓰는 것도 가능.  

* 데이터를 모아서 진행하는 배치 작업
* 구조화된 데이터를 가지고 하는 SQL 작업
* 지속적으로 발생하는 데이터를 적재 없이 처리하는 스트리밍 작업
* 분산 환경에서 대용량의 데이터를 기반으로 한 머신러닝 학습 및 추론 작업
* 그래프 데이터에 대한 병렬 연산

위 작업들을 하나의 엔진 안에서 처리할 수 있음.  
스파크는 저장소가 아니라서 외부의 데이터를 읽어 처리한 결과를 외부에 저장하는 형태임.  
외부 데이터 저장소는 파일 시스템과 데이터베이스를 가리지 않음.  
코드 레벨에서 분산 관련 고민을 할 필요를 덜어줌. 스파크가 제공하는 High-level API를 사용하면 스파크가 알아서 노드에 작업을 분산해줌.  

## 스파크 아키텍쳐

스파크는 분산 환경에서 연산 작업을 하는 것을 목표로 설계되었지만, 스파크 자체가 노드 별 자원 관리를 직접 하지는 않음.  
쿠버네티스, YARN, 메소스 등의 클러스터 매니징 솔루션을 통해 이를 진행함.  

![Images](../../Images/1-27.PNG)

굳이 이를 사용하지 않아도, 배포판에는 가벼운 버전의 클러스터 매니징 솔루션인 Spark Standalone 이라는 서비스를 포함함.  
Spark 코어는 작업 스케쥴링 및 오류 시 데이터 복구, 가용성 확보 전략을 포함함.  
Spark 코어 위에서 실제 연산을 수행하기 위한 많은 라이브러리들이 존재함.  
이러한 라이브러리들이 밖으로 드러나있지는 않고, 사용자는 API를 통해 스파크에 작업을 던져줄 코드를 짜게 되면 내부에서 알아서 돌아가는 형태.  

## 스파크 특징

* In-Memory 컴퓨팅 (Disk 기반도 가능)
* RDD(Resilient Distributed Dataset) 데이터 모델
* 대화형 질의를 위한 Interactive Shell 지원
* Realtime Stream Processing

## RDD란?

`Resilient Distributed Dataset.`  

* Resilient: 클러스터의 한 노드가 실패하더라도 다른 노드에서 작업 처리
* Distributed: RDD 안의 데이터는 클러스터에 자동 분배
* Dataset: 분산 저장된 변경 불가능한 데이터 객체 모음

RDD 측에서 제공하는 동작 API는 두 가지임.  

* Transformations: 데이터 변형 (map, filter, groupBy, join)  
이 경우, Action 실행 전까지 실제 변형은 미뤄두고, Action이 call 되면 그 때 변형을 수행함(= Lazy Evaluation).  
왜냐? 여러 변형 동작이 중복되거나 사용되지 않을 수 있으므로, 최적화를 위해 변형 동작을 DAG로 구성하여 최대한 적은 연산을 수행하게 함.  
* Actions: 결과 연산 및 리턴 (count, collect, save)

RDD의 일반적인 데이터 처리는 3단계로 이뤄짐: 생성, 변형, 연산  
보다 상세한 과정은 아래와 같음.

![Images](../../Images/1-28.PNG)

1. 맨 처음에 데이터를 확보함. 그림에서는 로그 파일.
2. 사용자가 원하는 만큼 데이터를 변형하는데, 이 때 마다 새로운 RDD 데이터가 생성됨.
3. 최종적으로 변환이 끝난 RDD 데이터를 Action API를 call해서 처리함.
4. 처리가 끝나 리턴 된 데이터를 적재함. 그림에서는 텍스트 파일.

# 스파크의 지원 언어

* Scala
* Java
* Python
* R

![Images](../../Images/1-29.PNG)

스파크는 JVM 위에서 돌아가는 자바 기반 어플리케이션.  
일반적으로 파이썬보다는 스칼라/자바를 사용할 때 성능이 더 잘 나온다는 통계가 있음.  
스칼라/자바의 경우 바로 코드가 실행되지만, 파이썬 기반 코드의 경우 파이썬 인터프리터 프로세스와 JVM 간의 통신 오버헤드가 있기 때문이라고 분석함.  

# 스파크 Interactive Shell

스파크 클러스터에 접속이 가능한 클라이언트.  
클러스터 위에서 실행이 가능하고, 로컬에서 실행한 뒤 클러스터에 접속도 가능함.  

* bin/spark-shell: 스칼라 기반 쉘
* bin/pyspark: 파이썬 기반 쉘
* bin/sparkR: R 기반 쉘
* bin/spark-sql: SQL 기반 쉘

# 스파크 Web Notebook

쉘의 경우 간단하게 사용하기 좋지만 코드 저장이나 기억 기능이 없음.  
웹 노트북의 경우 코드 저장이 가능하고, 기록이 남아 장기적으로 사용하기 좋음.  
스파크에서는 아래와 같은 웹 기반 노트북 솔루션을 제공함.  

* Apache Zeppelin  
스파크 자체 제작, Python, Scala, Hive, SparkSQL 등의 언어 지원.  
쉘의 입력 방식을 거의 그대로 지원.  
강력한 그래프 기능을 자체 지원함.  
* Jupyter Notebook  
파이썬 코드를 실행하기 위한 범용적인 웹 노트북 솔루션.  
Pandas 등의 라이브러리를 바로 call하여 사용 가능.  
R과의 빠른 연동도 가능.
* RStudio Server
R 언어 코드를 실행하기 위한 웹 노트북 솔루션.  

# 스파크 관리용 웹 UI

관리용 웹 UI는 크게 아래 세 가지로 나뉨.  

* Driver (Spark Application): 스파크 어플리케이션 측에서 제공하는 UI.  
  * 어플리케이션의 대시보드 기능
  * 스케쥴러 활동 확인 가능
  * RDD 크기와 메모리 사용 현황
* History Server: 드라이버가 꺼져있을 때에도 스파크 관련 정보를 제공하는 서버 UI.  
* Cluster Manager: 스파크 Standalone / YARN 등이 제공하는 클러스터 자원 어플리케이션이 제공하는 UI.  

# 스파크 vs 맵리듀스 (스파크 친화적 자료...?)

맵리듀스는 기본적으로 HDFS에서 데이터를 읽고, 연산 결과를 HDFS에 저장함.  
데이터 연산은 맵과 리듀스 두 단계로 이루어지며, 필요 시 반복.  
데이터를 다룰 때 복제, 직렬화, 디스크 I/O가 불가피 하기에 성능 손해가 있음.  
때문에 반복 연산(ML, 그래프/네트워크 분석)이나 데이터 마이닝에 불리함.

스파크의 경우 반복적으로 사용하는 데이터를 인메모리에 캐싱하여 사용.  
맵 연산과 리듀스 연산의 두 단계에 얽매이지 않음.  

100 TB 빠르게 분류하는 벤치마크 결과.  

![Images](../../Images/1-30.PNG)

머신 러닝 트레이닝하는 과정에 걸리는 시간 결과.

![Images](../../Images/1-31.PNG)

사용성의 경우, 사용하는 코드 양이 스파크 쪽에 훨씬 간결하며, 맵리듀스 측에서는 map, reduce 함수만을 제공하고 상세한 데이터 처리 과정은 직접 구현해야 하지만, 스파크 측에서는 High-level API로 join, sorting 등의 기능을 기본으로 제공함.  

![Images](../../Images/1-32.PNG)

# 스파크 아키텍쳐 스타일

스파크는 우리가 만드는 프로그램에서 하나의 라이브러리처럼 동작하며, 하나의 어플리케이션에 하나의 인스턴스(= 드라이버)가 존재함.  

![Images](../../Images/1-33.PNG)

근본적으로 스파크 프로그램은 하나의 드라이버와 여러 개의 스파크 익시큐터로 구성됨.  

* 스파크 드라이버: 스파크 컨텍스트를 생성하는 클라이언트 쪽에 붙는 스파크 어플리케이션. 인스턴스라고 봐도 좋다!  
스파크 컨텍스트를 내부에 생성하고 유지함.
* 스파크 컨텍스트: 실질적으로 스파크 동작을 시작하는 컴포넌트. 스파크 클러스터와 실질적으로 통신하며, 실제 연산 모듈인 스파크 익시큐터의 생성을 클러스터에 요청함.  
* 스파크 익시큐터: 클라이언트 어플리케이션 쪽에 존재할 수도 있고, 클러스터 쪽 워커 노드의 쓰레드에 존재할 수 있음. 실질적으로 요청받은 연산을 수행함.  

클러스터의 경우, 아래 그림처럼 태스크의 의뢰와 수행, 결과 전달이 이루어짐.  

![Images](../../Images/1-34.PNG)

# 스파크 프로그래밍 모델

우리의 프로그램에서 스파크를 사용하고자 한다면, 먼저 프로그램 안에서 스파크 컨텍스트를 만들어야 함.

```
sc = SparkContext()
rdd = sc.textFile("hdfs://...")
rdd2 = rdd.filter(...)
rdd3 = rdd2.re파티션(100)
rdd4 = rdd3.flatMap(...)
rdd5 = rdd4.map(...)
rdd5.cache()
```

위와 같은 코드가 있다고 생각해보자.  
filter, flatMap, map 등의 함수는 HDFS에서 불러온 원본 데이터의 형태를 변환하는 Transformations 함수.  
cache 등의 함수는 현재 RDD를 디스크나 메모리에 저장하기 위한 Persistence 함수.  
count, collect, reduce 등의 함수는 RDD를 기반으로 연산을 수행해 결과를 스토리지로 추출하는 함수.  

![Images](../../Images/1-35.PNG)

# 스파크 파티션

파티션은 RDDs나 데이터 셋을 구성하고 있는 최소 단위 객체.  
각 파티션은 서로 다른 노드에서 분산 처리 된다.  
Spark에서는 하나의 최소 연산을 태스크라고 표현하는데, 이 하나의 태스크에서 하나의 파티션이 처리하며, 하나의 태스크는 하나의 코어가 연산 처리한다.  

즉, 1 코어 = 1 태스크 = 1 파티션.  

예를 들어, 다음과 같다면 전체 코어 수를 300개로 세팅한 상태이고, 이 300개가 현재 실행 중인 태스크 수이자, 현재 처리 중인 파티션 수에 해당한다.  
또한, 전체 Patition 수는 1800개로 세팅했으며, 이는 전체 태스크 수와 같음.  

![Images](https://tech.kakao.com/wp-content/uploads/2022/01/01-12.png)

이처럼 설정된 파티션 수에 따라 각 파티션의 크기가 결정됨.  
그리고 이 파티션의 크기가 결국 코어 당 필요한 메모리 크기를 결정.

```
파티션 수 → 코어 수
파티션 크기 → 메모리 크기
```

따라서, 파티션의 크기와 수가 Spark 성능에 큰 영향을 미치는데, 통상적으로는 파티션의 크기가 클수록 메모리가 더 필요하고, 파티션의 수가 많을수록 코어가 더 필요하다.

```
적은 수의 파티션 = 크기가 큰 파티션
많은 수의 파티션 = 크기가 작은 파티션
```

즉, 파티션의 수를 늘리는 것은 태스크 당 필요한 메모리를 줄이고 병렬화의 정도를 늘리는 것.

(출처: https://tech.kakao.com/2021/10/08/spark-shuffle-partition/)

# RDD - Lazy Evaluation + Cache

위에서 Transformations 기능과 Action 기능에 대해 설명할 때, 실제 RDD의 Transformation은 Action 기능이 돌아갈 때 이뤄진다고 언급했음.  
이 과정에서 캐싱이 성능 향상에 얼마나 큰 영향을 끼치는지 알아보자.  

![Images](../../Images/1-36.PNG)

![Images](../../Images/1-37.PNG)

# RDD - 오류 시 데이터 복구 (Fault Tolerance)

스파크에서는 리니지라는 개념을 사용.  
한 RDD가 어떤 소스로부터 가져와져서 어떤 함수를 거쳤는지 경과를 기록하는데, 이를 리니지라고 표현함.  

![Images](https://alklid.github.io/dlog/assets/img/2017-10-12-spark-01_apache-storm-vs-spark-streaming-two-stream-processing-platforms-compared-36-638.jpg)

따라서 연산 시 오류가 발생할 경우, 이 리니지를 따라 처음부터 재연산을 수행함.  
만약 해당 파티션을 담당하던 노드가 아예 응답이 없다면, 다른 노드에서 처음부터 데이터를 읽어와 연산을 수행함.  

# 스파크의 내부 동작

우리가 RDD를 생성해서 연산을 수행하면 아래와 같은 동작으로 내부 처리가 됨.  

![Images](https://hxquangnhat.files.wordpress.com/2015/03/scheduling.jpeg)

RDD에 엮인 Transformation 연산들이 DAG 형태의 연산자로 생성되고, 이 DAG를 컴파일함.  
DAG는 여러 단계의 태스크로 쪼개지는데, 각각의 단일 태스크는 태스크 스케쥴러에 의해 스케쥴링이 되는 형태.  

하나의 연산은 아래와 같이 정형화된 DAG 형태로 변환하는 규칙이 있음.  

![Images](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FchzOQA%2FbtqW4iDOtjK%2F5EESssWWJnY8LY3cK5Nek0%2Fimg.jpg)

