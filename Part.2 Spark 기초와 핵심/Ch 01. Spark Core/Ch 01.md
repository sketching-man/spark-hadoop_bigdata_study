# 스파크 App. 환경

## 스파크 어플리케이션 구성

* 드라이버 프로그램 (로컬)
* 드라이버 프로그램 + 익시큐터 (클러스터)
* 모두가 각각 독립된 JVM 프로세스!

![Images](../../Images/1-34.PNG)

### 드라이버 프로그램

메인 함수가 실행되는 프로세스이며, 사용자 코드를 태스크로 변환하여 클러스터로 전송함.  

1. 연산들의 관계를 DAG(Directed Acyclic Graph)로 생성
2. DAG를 물리적인 실행 계획으로 변환  
최적화를 거쳐 여러개의 스테이지로 변환되며, 각 스테이지는 여러 태스크로 구성
3. 단위 작업을 묶어서 클러스터로 전송

익시큐터에서 태스크가 도는 타이밍의 스케쥴링/모니터링도 담당!

* 익시큐터들은 시작 시 드라이버에 등록.
* 드라이버는 항상 실행 중인 익시큐터를 감시.
* 웹 UI를 통해 실행 정보 제공.

### 익시큐터

개별 태스크를 워커 노드에서 실행하는 프로세스임.  
태스크 실행 이후 결과를 드라이버로 전송하며, 캐시하는 RDD를 저장하기 위한 메모리 공간이 실제로 위치하는 곳이기도 함.  

드라이버 프로그램은 익시큐터를 할당받기 위해 클러스터 매니저(Standalone, Mesos, YARN, K8s)에 요청함.  

## 스파크 어플리케이션 배포

* spark-submit(스크립트), launcher(API)
* Local, (이후 모두 클러스터 대상 매니저)Standalone, Mesos, YARN, K8s

일반적인 케이스의 스파크 어플리케이션 라이프 사이클은 아래와 같음.  

1. spark-submit 이용해 어플리케이션 제출
2. spark-submit은 드라이버 프로그램 실행, 메인 함수 호출
3. 드라이버 프로그램이 클러스터 매니저에게 익시큐터 실행을 위한 리소스 요청
4. 클러스터 매니저가 익시큐터 실행
5. 드라이버 프로그램이 작업을 태스크 단위로 나누어 익시큐터에게 전송
6. 익시큐터가 태스크 실행, 결과를 드라이버에게 반환
7. 어플리케이션이 종료되면 클러스터 매니저에게 리소스 반납

## 스파크 어플리케이션 개발

* RDD 생성 → RDD 변환 → RDD 연산/저장
* Spark Shell, Web Notebook, IDE

